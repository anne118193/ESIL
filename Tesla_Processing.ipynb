{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678da611",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/ESL/data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_98/3635836754.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m \u001b[0mgetAhAndCaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoc_curve_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misCalendarAging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_98/3635836754.py\u001b[0m in \u001b[0;36mgetAhAndCaps\u001b[0;34m(data_file_path, cell_num, soc_curve_file, summary_file, cc, isCalendarAging)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# import data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m# data2= pd.read_csv(data_file_path_2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# data = data.append(data2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/ESL/data.csv'"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "#from openpyxl import load_workbook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def getAhAndCaps(data_file_path, cell_num, soc_curve_file, summary_file, cc, isCalendarAging=False):\n",
    "    # This function imports raw test data, calculates test results (discharge amp hours and cell capacites), \n",
    "    # and then appends the test results to an ongoing summary file\n",
    "    \n",
    "    # import data\n",
    "    data = pd.read_csv(data_file_path)\n",
    "    # data2= pd.read_csv(data_file_path_2)\n",
    "    # data = data.append(data2)\n",
    "\n",
    "    # remove rows with duplicate timestamps\n",
    "    data = data.drop_duplicates(subset=['Time'])\n",
    "\n",
    "    # get all cell voltages\n",
    "\n",
    "    # first pack in series\n",
    "    n=0\n",
    "    cell_voltages = data.iloc[:, 15 + n:15 + n + cell_num].to_numpy()\n",
    "\n",
    "    # second pack in series\n",
    "    # n = 6\n",
    "    # cell_voltages = data.iloc[:, 15 + n:15 + n + cell_num].to_numpy()\n",
    "\n",
    "    # third pack in series\n",
    "    # n = 12\n",
    "    # cell_voltages = data.iloc[:, 15 + n:15 + n + cell_num].to_numpy()\n",
    "\n",
    "\n",
    "    # pack voltage and current\n",
    "    Vpack = data[' Pack Voltage'].to_numpy()\n",
    "    Ipack = data[' Pack Current'].to_numpy()\n",
    "\n",
    "    # create Step array - each 'Step' corresponds to a sequential command in the Digatron test setup \n",
    "    #    (eg \"10 A for 5 seconds\", \"40 A for 10 minutes\", etc)\n",
    "    Step = []\n",
    "    for i in range(len(Ipack)-1):\n",
    "        if Ipack[i]!=0 and Ipack[i+1]==0:\n",
    "            Step = np.append(Step,i+1)\n",
    "        elif Ipack[i]==0 and Ipack[i+1]!=0:\n",
    "            Step = np.append(Step,i+1)\n",
    "\n",
    "       # ---- Plotting in case results are defective -------\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(Ipack, label='current')\n",
    "    ax.plot(cell_voltages[:, 0], label='voltage')\n",
    "    dots = [Ipack[int(s)] for s in Step[:]]\n",
    "    ax.scatter(Step[:], dots, color='red')\n",
    "    # ax.scatter(Step[start_idx], StartVs[0], color='black')\n",
    "    # ax.scatter(Step[end_idx], EndVs[0], color='black')\n",
    "\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    # --------to remove range of values---------------\n",
    "    # print(cell_voltages.shape)\n",
    "    #\n",
    "    # cell_v1 = cell_voltages[0:int(Step[8]), :]\n",
    "    # length = len(cell_voltages)-1\n",
    "    # cell_v2 = cell_voltages[int(Step[10]):length, :]\n",
    "    # cell_voltages = np.concatenate((cell_v1, cell_v2), axis=0)\n",
    "    # numpy.savetxt('new_aging_27.csv', cell_voltages)\n",
    "    # #\n",
    "    # # print(cell_voltages.shape)\n",
    "    # #\n",
    "    # I1 = Ipack[0:int(Step[8])]\n",
    "    # length = len(Ipack)-1\n",
    "    # I2 = Ipack[int(Step[10]):length]\n",
    "    # Ipack = np.concatenate((I1,I2),axis=0)\n",
    "    # #\n",
    "    # # # must recreate steps\n",
    "    # Step = []\n",
    "    # for i in range(len(Ipack) - 1):\n",
    "    #     if Ipack[i] != 0 and Ipack[i + 1] == 0:\n",
    "    #         Step = np.append(Step, i + 1)\n",
    "    #     elif Ipack[i] == 0 and Ipack[i + 1] != 0:\n",
    "    #         Step = np.append(Step, i + 1)\n",
    "    # ---------------------end of range elimination--------------------\n",
    "\n",
    "    # get StartVs, EndVs\n",
    "    start_idx = 16\n",
    "    end_idx = start_idx + 6\n",
    "    StartVs = cell_voltages[int(Step[start_idx]-1),:]  # get the voltage at the height of the CCCV curve after constant voltage\n",
    "    EndVs = cell_voltages[int(Step[end_idx]-1),:]  # get the voltage at the end of the CCCV curve after constant current discharge\n",
    "    # interpolate OCV-SOC curve to get SOCstart and SOCend values corresponding to StartVs and EndVs\n",
    "    soc_curve = pd.read_csv(soc_curve_file)\n",
    "    ocv = soc_curve.iloc[:,0].values.astype(float)\n",
    "    soc = soc_curve.iloc[:,1].values.astype(float)\n",
    "    ocv2=ocv[::-1]\n",
    "    soc2=soc[::-1]\n",
    "    v_i1 = cell_voltages[int(Step[2]),:]\n",
    "    v_i2 = cell_voltages[int(Step[3]),:]\n",
    "    endSOC= np.interp(EndVs, ocv2, soc2)\n",
    "    startSOC= np.interp(StartVs, ocv2, soc2)\n",
    "\n",
    "    #cell voltage imbalance\n",
    "    CCCV_voltage = np.array(cell_voltages[int(Step[16]-1):int(Step[22]-1), :])\n",
    "    std_indiv = np.std(CCCV_voltage, axis=1)\n",
    "    std_final = np.mean(std_indiv, axis=0)\n",
    "    print('std_ccv +', std_final)\n",
    "    print('startv +', np.mean(StartVs))\n",
    "    print('endv +', np.mean(EndVs))\n",
    "    print('i1 +', np.mean(v_i1))\n",
    "    print('i2 +', np.mean(v_i2))\n",
    "    # integrate discharge current to get discharge amp hours\n",
    "    datetime_object = [dt.datetime.strptime(d[0:20]+d[24:28], '%a %b %d %H:%M:%S %Y') for d in data['Time']]\n",
    "    tmstmp = [t.timestamp()/3600 for t in datetime_object]\n",
    "    ahDch = np.zeros(len(Ipack)-1)\n",
    "    for i in range(len(Ipack)-2):\n",
    "        if Ipack[i+1]>0:    # calcualte ahDch for positive values of current only (positive = discharge)\n",
    "            ahDch[i+1] = ahDch[i] + .5*(tmstmp[i+2]-tmstmp[i+1])*(Ipack[i+2]+Ipack[i+1])\n",
    "        else:\n",
    "            ahDch[i+1] = ahDch[i]\n",
    "    DCH1 = ahDch[int(Step[start_idx])]\n",
    "    DCHTotal = ahDch[-1]\n",
    "    DCH2 = DCHTotal - DCH1\n",
    "    # based on CC (const curr.) as specified by the Digatron test\n",
    "    CapDchAh = cc*(tmstmp[int(Step[start_idx+1])]-tmstmp[int(Step[start_idx])])\n",
    "\n",
    "    # print test start and end dates for logging purposes\n",
    "    print('start: ' + data['Time'].iloc[0])\n",
    "    print('end: ' + data['Time'].iloc[-1]) \n",
    "\n",
    "    # calculate individual cell capacities\n",
    "    Cap = np.zeros((len(startSOC,)))\n",
    "    for i in range(len(Cap)):\n",
    "        Cap[i] = (100/(startSOC[i]-endSOC[i]))*CapDchAh\n",
    "\n",
    "    # determine test name\n",
    "    test_name = data_file_path.split('_')\n",
    "    test_name = test_name[-1].split('.')\n",
    "\n",
    "    if isCalendarAging: \n",
    "        # get NP number\n",
    "        x = re.findall(\"T1-\\d+\", data_file_path)\n",
    "        TPname = x[0]\n",
    "        # import summary from correct sheet name\n",
    "        summary = pd.read_excel(summary_file, sheet_name=TPname)\n",
    "        test_name = 'char ' + str(summary.shape[0]+1)\n",
    "        # get end_date\n",
    "        end_date = datetime_object[-1]\n",
    "        # get days_elapsed\n",
    "        previous_test = dt.datetime.strptime(summary['test_end_date'].iloc[0], '%Y-%m-%d ')\n",
    "        days_elapsed = (datetime_object[0] - previous_test).days\n",
    "        # days_elapsed = 0\n",
    "        # import summary csv, append new summary, save as csv\n",
    "        summary_updated = np.concatenate([np.array([test_name, end_date.strftime('%Y-%m-%d '), days_elapsed, DCH1, DCH2]), Cap])\n",
    "        # summary_updated = np.concatenate([np.array([test_name, end_date.strftime('%-m/%-d/%Y'), days_elapsed, DCH1, DCH2]), Cap])\n",
    "        summary.loc[len(summary)] = summary_updated\n",
    "        # summary.to_excel(summary_file, sheet_name = NPname, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        # open excel sheet with ExcelWriter to avoid overwritting other sheets\n",
    "        book = load_workbook(summary_file)\n",
    "        writer = pd.ExcelWriter(summary_file, engine='openpyxl') \n",
    "        writer.book = book\n",
    "        writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "        summary.to_excel(writer, TPname, index=False)\n",
    "        writer.save()\n",
    "\n",
    "    else: \n",
    "        # import summary csv, append new summary, save as csv\n",
    "        summary = pd.read_csv(summary_file)\n",
    "        summary_updated = np.concatenate([np.array([test_name[0], DCH1, DCH2]), Cap])\n",
    "        summary.loc[len(summary)] = summary_updated\n",
    "        summary.to_csv(summary_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------ General Tesla Info ------------------------------\n",
    "# path to test summary file\n",
    "summary_file = r'/ESL/Tesla_test_summary.csv'\n",
    "\n",
    "# path to OCV-SOC csv file\n",
    "soc_curve_file = r'/ESL/TeslaOCVcurve_matt.csv'\n",
    "\n",
    "# number of total cells in test (3 modules each with 6 cells)\n",
    "cell_num=18     \n",
    "\n",
    "# Value of constant current during characteriations\n",
    "cc = 40\n",
    "\n",
    "# set n to signify which battery is being processed in series\n",
    "# if cycle aging or first in calendar\n",
    "n = 0\n",
    "# second in calendar\n",
    "#n = 6\n",
    "# third in calendar\n",
    "#n = 12\n",
    "\n",
    "\n",
    "# ------------------------------------ Tesla Cycle Aging ------------------------------\n",
    "# path to where raw test csv is stored\n",
    "path = r'/ESL/'\n",
    "# path = r'F:/Tesla Data/'\n",
    "# name of csv file\n",
    "data_file = r'cellvoltages_2022-07-08-12-02-13_T1-12_100.csv'\n",
    "data_file_path = path + data_file\n",
    "# data_file2 = r'Tesla_Aging16_2.csv'\n",
    "# data_file_path_2 = path + data_file2\n",
    "\n",
    "# getAhAndCaps(data_file_path, cell_num, soc_curve_file, summary_file, cc, n)\n",
    "\n",
    "\n",
    "# ------------------------------------ Tesla Calendar Aging ------------------------------\n",
    "# path to test summary file\n",
    "summary_file = r'/ESL/Tesla_test_summary_calendar.xlsx'\n",
    "cell_num = 6\n",
    "\n",
    "# path to where raw test csv is stored\n",
    "path = r'/ESL/'\n",
    "\n",
    "# # T1-3\n",
    "# data_file = r'December_T1-3_50.csv'\n",
    "# data_file = r'T1-3_50.csv'\n",
    "# data_file_path = path + 'T1-3/' + data_file\n",
    "# data_file2 = r'December_T1-3_50_2.csv'\n",
    "# data_file_path_2 = path + 'T1-3/' + data_file2\n",
    "\n",
    "# # T1-9\n",
    "# data_file = r'T1-9_75SOC.csv'\n",
    "# data_file_path = path + 'T1-9/' + data_file\n",
    "\n",
    "# T1-10\n",
    "# data_file = r'T1-10_90SOC.csv'\n",
    "# data_file_path = path + 'T1-10/' + data_file\n",
    "\n",
    "# T1-12\n",
    "# data_file = r'T1-12_100SOC.csv'\n",
    "# data_file_path = path + 'T1-12/' + data_file\n",
    "\n",
    "#\n",
    "getAhAndCaps(data_file_path, cell_num, soc_curve_file, summary_file, cc, isCalendarAging=True)\n",
    "\n",
    "\n",
    "# ------------------------- For Processing Multiple Files ---------------------\n",
    "# folder = r'/Users/quiana/Documents/UCSD/CER/Data_Processing/Data/Tesla/csvs/'\n",
    "# # logs = [l[2] for l in os.walk(folder) if len(l[2])>len('.DS_Store')]\n",
    "# logs = [l[2] for l in os.walk(folder)]\n",
    "# if '.DS_Store' in logs[0]: logs[0].remove('.DS_Store')\n",
    "# csvs = logs[0]\n",
    "\n",
    "# for l in logs[0]:\n",
    "#     data_file_path = folder + l\n",
    "#     getAhAndCaps(data_file_path, cell_num, soc_curve_file, summary_file)\n",
    "#     print(l)\n",
    "\n",
    "# os.system('say \"ding ding ding ding Im done ding ding ding ding Im done\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
